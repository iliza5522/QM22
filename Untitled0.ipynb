{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iliza5522/QM22/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ8XO9O-rcJ-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install spacy\n",
        "!pip install scattertext\n",
        "!pip install tika\n",
        "!pip install spacytextblob\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install pyLDAvis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from gensim.models import LdaModel\n",
        "import nltk\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "\n",
        "import spacy\n",
        "import json\n",
        "import pylab\n",
        "from IPython.core.display import display, HTML\n",
        "import nltk\n",
        "from tika import parser\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from spacytextblob.spacytextblob import SpacyTextBlob\n",
        "\n",
        "%matplotlib inline\n",
        "pylab.rcParams['figure.figsize'] = (10., 8.)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe('spacytextblob')"
      ],
      "metadata": {
        "id": "eKZyJLDlgUOR",
        "outputId": "eefd8e5d-e6ab-40c0-e817-66e6ef4e1269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacytextblob.spacytextblob.SpacyTextBlob at 0x7b2cc3f510f0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    'https://merics.org/en/analysis/bri-pakistan-chinas-flagship-economic-corridor'\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "OFENFDTJoB6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_article(url):\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "  paragraphs = soup.find_all('p')\n",
        "  article_text = ' '.join([p.text for p in paragraphs])\n",
        "\n",
        "  return article_text\n",
        "\n",
        "articles = [scrape_article(url) for url in urls]\n",
        "\n"
      ],
      "metadata": {
        "id": "qDRZITAY5oDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'[a-z\\s]', '', text)\n",
        "  tokens = word_tokenize(text)\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
        "  return tokens\n",
        ""
      ],
      "metadata": {
        "id": "9cbMgwET6nIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_articles = [preprocess_text(article) for article in articles]\n",
        "dictionary = corpora.Dictionary(cleaned_articles)\n",
        "corpus = [dictionary.doc2bow(article) for article in cleaned_articles]\n",
        "\n",
        "lda_model = LdaModel(corpus, id2word=dictionary, num_topics=10, passes=20)\n",
        "\n",
        "topics = lda_model.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "  print(topic)"
      ],
      "metadata": {
        "id": "FdzX5fvz7Stv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}